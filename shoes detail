import requests
from bs4 import BeautifulSoup
#import csv
def get_page(url):
    response=requests.get(url)
    if response.ok:
        soup=BeautifulSoup(response.content,'lxml')
    else:
        print("Error in retreviewing page")
    return soup
def page_detail(soup):

    try:

        title=soup.find('span',class_="_35KyD6").text.replace('\xa0\xa0','')
    except:
        title=''
    try:
        price=soup.find(class_="_1vC4OE _3qQ9m1").text


    except:
        price=''
    try:
        discount=soup.find(class_="VGWI6T").text

    except:
        discount=''


    data={
        "Title":title,
        "Price": price,
        "Discount": discount,

    }
    return data
#def write_csv(data):
  #     writer=csv.writer(csvfile)
   #     row=[data['Title'],data['price'],data['discount'],data['Link']]
    #    writer.writerow(row)


def get_all_links(soup):
    try:
        links=soup.find_all('a',class_="_2mylT6")
    except:
        links=[]

    urls=[]
    for i in links:
        urls.append("https://www.flipkart.com" + i.get('href'))
    return urls
def main():
    url="https://www.flipkart.com/search?q=addidas%20shoes&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off"
    products=get_all_links(get_page(url))
    count=0
    final_data={}
    for item in products:
        data=page_detail(get_page(item))
        data.update({'Link':item})
        print(data)

    #print("Title","Price","Discount","Link")
    ##  print("{} {} {} {}".format(Title,Price,Discount,Link))
        #write_csv(data)
    #print(final_data)


if __name__=='__main__':
    main()
